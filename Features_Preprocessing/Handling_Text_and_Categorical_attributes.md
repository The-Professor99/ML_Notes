Most ML algorithms prefer to work with numbers so its sometimes useful converting categorical attributes from text to numbers.
Note also that ML algorithms will assume that two nearby values are more similar than two distant values(This may be fine in some cases such as the ordered categories of "bad", "average", "good", but isn't in cases such as a category of countries. For this reason, one-hot-encoding is commonly used.(see sklearn OrdinalEncoder and OneHotEncoder classes).

If a categorical attribute has a large number of possible categories (e.g., country code, profession, species), then one-hot encoding will result in a large number of input features. This may slow down training and degrade performance. If this happens, you may want to replace the categorical input with useful numerical features related to the categories: for example, you could replace the ocean_proximity feature with the distance to the ocean (similarly, a country code could be replaced with the countryâ€™s population and GDP per capita). Alternatively, you can use one of the encoders provided by the category_encoders package on [sklearn config](https://github.com/scikit-learn-contrib). Or when dealing with neural networks, you can replace each category with a learnable, low-dimensional vector called an embedding - This is an example of representation learning.